{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfM688cz-uSN",
        "outputId": "a601a51f-782a-49e5-d216-ae856c1651fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\mitta\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\mitta\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\mitta\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import the required libraries\n",
        "\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as num\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tensorF\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Downloads\\ai term paper\\AI-chatbot\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\mitta\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\banking77\\9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4\\banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(\"banking77\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [\n",
        "    \"activate_my_card\",\n",
        "    \"age_limit\",\n",
        "    \"apple_pay_or_google_pay\",\n",
        "    \"atm_support\",\n",
        "    \"automatic_top_up\",\n",
        "    \"balance_not_updated_after_bank_transfer\",\n",
        "    \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
        "    \"beneficiary_not_allowed\",\n",
        "    \"cancel_transfer\",\n",
        "    \"card_about_to_expire\",\n",
        "    \"card_acceptance\",\n",
        "    \"card_arrival\",\n",
        "    \"card_delivery_estimate\",\n",
        "    \"card_linking\",\n",
        "    \"card_not_working\",\n",
        "    \"card_payment_fee_charged\",\n",
        "    \"card_payment_not_recognised\",\n",
        "    \"card_payment_wrong_exchange_rate\",\n",
        "    \"card_swallowed\",\n",
        "    \"cash_withdrawal_charge\",\n",
        "    \"cash_withdrawal_not_recognised\",\n",
        "    \"change_pin\",\n",
        "    \"compromised_card\",\n",
        "    \"contactless_not_working\",\n",
        "    \"country_support\",\n",
        "    \"declined_card_payment\",\n",
        "    \"declined_cash_withdrawal\",\n",
        "    \"declined_transfer\",\n",
        "    \"direct_debit_payment_not_recognised\",\n",
        "    \"disposable_card_limits\",\n",
        "    \"edit_personal_details\",\n",
        "    \"exchange_charge\",\n",
        "    \"exchange_rate\",\n",
        "    \"exchange_via_app\",\n",
        "    \"extra_charge_on_statement\",\n",
        "    \"failed_transfer\",\n",
        "    \"fiat_currency_support\",\n",
        "    \"get_disposable_virtual_card\",\n",
        "    \"get_physical_card\",\n",
        "    \"getting_spare_card\",\n",
        "    \"getting_virtual_card\",\n",
        "    \"lost_or_stolen_card\",\n",
        "    \"lost_or_stolen_phone\",\n",
        "    \"order_physical_card\",\n",
        "    \"passcode_forgotten\",\n",
        "    \"pending_card_payment\",\n",
        "    \"pending_cash_withdrawal\",\n",
        "    \"pending_top_up\",\n",
        "    \"pending_transfer\",\n",
        "    \"pin_blocked\",\n",
        "    \"receiving_money\",\n",
        "    \"Refund_not_showing_up\",\n",
        "    \"request_refund\",\n",
        "    \"reverted_card_payment?\",\n",
        "    \"supported_cards_and_currencies\",\n",
        "    \"terminate_account\",\n",
        "    \"top_up_by_bank_transfer_charge\",\n",
        "    \"top_up_by_card_charge\",\n",
        "    \"top_up_by_cash_or_cheque\",\n",
        "    \"top_up_failed\",\n",
        "    \"top_up_limits\",\n",
        "    \"top_up_reverted\",\n",
        "    \"topping_up_by_card\",\n",
        "    \"transaction_charged_twice\",\n",
        "    \"transfer_fee_charged\",\n",
        "    \"transfer_into_account\",\n",
        "    \"transfer_not_received_by_recipient\",\n",
        "    \"transfer_timing\",\n",
        "    \"unable_to_verify_identity\",\n",
        "    \"verify_my_identity\",\n",
        "    \"verify_source_of_funds\",\n",
        "    \"verify_top_up\",\n",
        "    \"virtual_card_not_working\",\n",
        "    \"visa_or_mastercard\",\n",
        "    \"why_verify_identity\",\n",
        "    \"wrong_amount_of_cash_received\",\n",
        "    \"wrong_exchange_rate_for_cash_withdrawal\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of intent classes: 77\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of intent classes:\", len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_text_mapping = {}\n",
        "\n",
        "for label in labels:\n",
        "    labels_text_mapping[label] = []\n",
        "\n",
        "for curr_data in data[\"train\"]:\n",
        "    labels_text_mapping[labels[curr_data[\"label\"]]].append(curr_data[\"text\"])\n",
        "\n",
        "\n",
        "final_data = {\"intents\": []}\n",
        "\n",
        "for curr_data_key in labels_text_mapping:\n",
        "    mapping = {\n",
        "        \"tag\": curr_data_key,\n",
        "        \"patterns\": labels_text_mapping[curr_data_key][:50],\n",
        "    }\n",
        "    final_data[\"intents\"].append(mapping)\n",
        "\n",
        "\n",
        "data = final_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of intent classes in dataset: 77\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of intent classes in dataset:\", len(data[\"intents\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QJkfSJBtx05X"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "data_classes = []\n",
        "words = []\n",
        "x = []\n",
        "y = []\n",
        "for i in data[\"intents\"]:\n",
        "    for j in i[\"patterns\"]:\n",
        "        tokens = nltk.word_tokenize(j)\n",
        "        words.extend(tokens)\n",
        "        x.append(j)\n",
        "        y.append(i[\"tag\"])\n",
        "\n",
        "    if i[\"tag\"] not in data_classes:\n",
        "        data_classes.append(i[\"tag\"])\n",
        "\n",
        "words = [\n",
        "    lemmatizer.lemmatize(word.lower())\n",
        "    for word in words\n",
        "    if word not in string.punctuation\n",
        "]\n",
        "words = sorted(set(words))\n",
        "data_classes = sorted(set(data_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Refund_not_showing_up',\n",
              " 'activate_my_card',\n",
              " 'age_limit',\n",
              " 'apple_pay_or_google_pay',\n",
              " 'atm_support',\n",
              " 'automatic_top_up',\n",
              " 'balance_not_updated_after_bank_transfer',\n",
              " 'balance_not_updated_after_cheque_or_cash_deposit',\n",
              " 'beneficiary_not_allowed',\n",
              " 'cancel_transfer',\n",
              " 'card_about_to_expire',\n",
              " 'card_acceptance',\n",
              " 'card_arrival',\n",
              " 'card_delivery_estimate',\n",
              " 'card_linking',\n",
              " 'card_not_working',\n",
              " 'card_payment_fee_charged',\n",
              " 'card_payment_not_recognised',\n",
              " 'card_payment_wrong_exchange_rate',\n",
              " 'card_swallowed',\n",
              " 'cash_withdrawal_charge',\n",
              " 'cash_withdrawal_not_recognised',\n",
              " 'change_pin',\n",
              " 'compromised_card',\n",
              " 'contactless_not_working',\n",
              " 'country_support',\n",
              " 'declined_card_payment',\n",
              " 'declined_cash_withdrawal',\n",
              " 'declined_transfer',\n",
              " 'direct_debit_payment_not_recognised',\n",
              " 'disposable_card_limits',\n",
              " 'edit_personal_details',\n",
              " 'exchange_charge',\n",
              " 'exchange_rate',\n",
              " 'exchange_via_app',\n",
              " 'extra_charge_on_statement',\n",
              " 'failed_transfer',\n",
              " 'fiat_currency_support',\n",
              " 'get_disposable_virtual_card',\n",
              " 'get_physical_card',\n",
              " 'getting_spare_card',\n",
              " 'getting_virtual_card',\n",
              " 'lost_or_stolen_card',\n",
              " 'lost_or_stolen_phone',\n",
              " 'order_physical_card',\n",
              " 'passcode_forgotten',\n",
              " 'pending_card_payment',\n",
              " 'pending_cash_withdrawal',\n",
              " 'pending_top_up',\n",
              " 'pending_transfer',\n",
              " 'pin_blocked',\n",
              " 'receiving_money',\n",
              " 'request_refund',\n",
              " 'reverted_card_payment?',\n",
              " 'supported_cards_and_currencies',\n",
              " 'terminate_account',\n",
              " 'top_up_by_bank_transfer_charge',\n",
              " 'top_up_by_card_charge',\n",
              " 'top_up_by_cash_or_cheque',\n",
              " 'top_up_failed',\n",
              " 'top_up_limits',\n",
              " 'top_up_reverted',\n",
              " 'topping_up_by_card',\n",
              " 'transaction_charged_twice',\n",
              " 'transfer_fee_charged',\n",
              " 'transfer_into_account',\n",
              " 'transfer_not_received_by_recipient',\n",
              " 'transfer_timing',\n",
              " 'unable_to_verify_identity',\n",
              " 'verify_my_identity',\n",
              " 'verify_source_of_funds',\n",
              " 'verify_top_up',\n",
              " 'virtual_card_not_working',\n",
              " 'visa_or_mastercard',\n",
              " 'why_verify_identity',\n",
              " 'wrong_amount_of_cash_received',\n",
              " 'wrong_exchange_rate_for_cash_withdrawal']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1564"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"''\",\n",
              " \"'d\",\n",
              " \"'declined\",\n",
              " \"'m\",\n",
              " \"'re\",\n",
              " \"'s\",\n",
              " \"'ve\",\n",
              " '--',\n",
              " '-up',\n",
              " '..',\n",
              " '...',\n",
              " '1',\n",
              " '10',\n",
              " '100',\n",
              " '16',\n",
              " '18',\n",
              " '1818',\n",
              " '1£',\n",
              " '2',\n",
              " '20',\n",
              " '20.00',\n",
              " '2018',\n",
              " '30',\n",
              " '3d',\n",
              " '5',\n",
              " '500',\n",
              " '500£',\n",
              " '5x',\n",
              " '6',\n",
              " '60',\n",
              " '8',\n",
              " '80',\n",
              " '``',\n",
              " 'a',\n",
              " 'able',\n",
              " 'about',\n",
              " 'abroad',\n",
              " 'accept',\n",
              " 'acceptable',\n",
              " 'accepted',\n",
              " 'accepting',\n",
              " 'accepts',\n",
              " 'access',\n",
              " 'accessed',\n",
              " 'accessing',\n",
              " 'accident',\n",
              " 'accidentally',\n",
              " 'according',\n",
              " 'account',\n",
              " 'accurate',\n",
              " 'achieve',\n",
              " 'acquiring',\n",
              " 'across',\n",
              " 'activate',\n",
              " 'activated',\n",
              " 'activating',\n",
              " 'activation',\n",
              " 'active',\n",
              " 'activity',\n",
              " 'actual',\n",
              " 'actually',\n",
              " 'add',\n",
              " 'added',\n",
              " 'adding',\n",
              " 'additional',\n",
              " 'additionally',\n",
              " 'address',\n",
              " 'adjusted',\n",
              " 'adress',\n",
              " 'advise',\n",
              " 'afraid',\n",
              " 'after',\n",
              " 'again',\n",
              " 'age',\n",
              " 'aggravated',\n",
              " 'ago',\n",
              " 'ahead',\n",
              " 'ahold',\n",
              " 'alert',\n",
              " 'all',\n",
              " 'allow',\n",
              " 'allowable',\n",
              " 'allowed',\n",
              " 'allowing',\n",
              " 'almost',\n",
              " 'along',\n",
              " 'already',\n",
              " 'alright',\n",
              " 'also',\n",
              " 'alternative',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'american',\n",
              " 'amount',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'anticipated',\n",
              " 'any',\n",
              " 'anymore',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyting',\n",
              " 'anyway',\n",
              " 'anywhere',\n",
              " 'app',\n",
              " 'apparently',\n",
              " 'appear',\n",
              " 'appeared',\n",
              " 'appearing',\n",
              " 'appears',\n",
              " 'appiled',\n",
              " 'apple',\n",
              " 'applicable',\n",
              " 'application',\n",
              " 'applied',\n",
              " 'apply',\n",
              " 'appreciate',\n",
              " 'appropriate',\n",
              " 'approve',\n",
              " 'approved',\n",
              " 'approximately',\n",
              " 'apps',\n",
              " 'are',\n",
              " 'area',\n",
              " 'around',\n",
              " 'arrive',\n",
              " 'arrived',\n",
              " 'as',\n",
              " 'asap',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'asking',\n",
              " 'assessed',\n",
              " 'assign',\n",
              " 'assist',\n",
              " 'assistance',\n",
              " 'assisted',\n",
              " 'associated',\n",
              " 'assumed',\n",
              " 'at',\n",
              " 'ate',\n",
              " 'atm',\n",
              " 'atmosphere',\n",
              " 'attempt',\n",
              " 'attempted',\n",
              " 'attempting',\n",
              " 'attended',\n",
              " 'aud',\n",
              " 'austria',\n",
              " 'authenticate',\n",
              " 'authentication',\n",
              " 'authorise',\n",
              " 'authorization',\n",
              " 'authorize',\n",
              " 'auto',\n",
              " 'auto-top',\n",
              " 'automatic',\n",
              " 'automatically',\n",
              " 'available',\n",
              " 'average',\n",
              " 'avoid',\n",
              " 'avoided',\n",
              " 'aware',\n",
              " 'away',\n",
              " 'awful',\n",
              " 'awhile',\n",
              " 'back',\n",
              " 'bad',\n",
              " 'bad.this',\n",
              " 'bag',\n",
              " 'balance',\n",
              " 'bank',\n",
              " 'banking',\n",
              " 'based',\n",
              " 'basic',\n",
              " 'basis',\n",
              " 'bay',\n",
              " 'be',\n",
              " 'because',\n",
              " 'becomes',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'believe',\n",
              " 'beneficiary',\n",
              " 'beneficiery',\n",
              " 'besides',\n",
              " 'best',\n",
              " 'better',\n",
              " 'between',\n",
              " 'bill',\n",
              " 'billed',\n",
              " 'billing',\n",
              " 'bit',\n",
              " 'block',\n",
              " 'blocked',\n",
              " 'blocking',\n",
              " 'blur',\n",
              " 'blurring',\n",
              " 'bos',\n",
              " 'both',\n",
              " 'bough',\n",
              " 'bought',\n",
              " 'brand',\n",
              " 'break',\n",
              " 'broke',\n",
              " 'broken',\n",
              " 'brought',\n",
              " 'bulk',\n",
              " 'bunch',\n",
              " 'bus',\n",
              " 'business',\n",
              " 'but',\n",
              " 'button',\n",
              " 'buy',\n",
              " 'buying',\n",
              " 'by',\n",
              " 'ca',\n",
              " 'calculate',\n",
              " 'calculated',\n",
              " 'call',\n",
              " 'calling',\n",
              " 'came',\n",
              " 'can',\n",
              " 'cancel',\n",
              " 'canceled',\n",
              " 'canceling',\n",
              " 'cancelled',\n",
              " 'cant',\n",
              " 'car',\n",
              " 'card',\n",
              " 'care',\n",
              " 'careful',\n",
              " 'carry',\n",
              " 'case',\n",
              " 'cash',\n",
              " 'cat',\n",
              " 'cause',\n",
              " 'caused',\n",
              " 'causing',\n",
              " 'center',\n",
              " 'centre',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'chance',\n",
              " 'change',\n",
              " 'changed',\n",
              " 'changing',\n",
              " 'charge',\n",
              " 'charged',\n",
              " 'charging',\n",
              " 'check',\n",
              " 'checked',\n",
              " 'checking',\n",
              " 'cheque',\n",
              " 'child',\n",
              " 'china',\n",
              " 'choice',\n",
              " 'choose',\n",
              " 'chose',\n",
              " 'chosen',\n",
              " 'city',\n",
              " 'claim',\n",
              " 'clarify',\n",
              " 'clear',\n",
              " 'cleared',\n",
              " 'clearly',\n",
              " 'cloned',\n",
              " 'close',\n",
              " 'closed',\n",
              " 'closest',\n",
              " 'closing',\n",
              " 'clue',\n",
              " 'code',\n",
              " 'college',\n",
              " 'color',\n",
              " 'come',\n",
              " 'comfortable',\n",
              " 'coming',\n",
              " 'common',\n",
              " 'company',\n",
              " 'complete',\n",
              " 'completed',\n",
              " 'completely',\n",
              " 'completing',\n",
              " 'completion',\n",
              " 'compromised',\n",
              " 'concern',\n",
              " 'concerned',\n",
              " 'concerning',\n",
              " 'condition',\n",
              " 'configured',\n",
              " 'confirm',\n",
              " 'confirmed',\n",
              " 'confirming',\n",
              " 'confused',\n",
              " 'contact',\n",
              " 'contacted',\n",
              " 'contactless',\n",
              " 'contained',\n",
              " 'contains',\n",
              " 'continue',\n",
              " 'continuously',\n",
              " 'convert',\n",
              " 'cool',\n",
              " 'copied',\n",
              " 'copy',\n",
              " 'correct',\n",
              " 'correctly',\n",
              " 'cost',\n",
              " 'could',\n",
              " 'couldnt',\n",
              " 'country',\n",
              " 'couple',\n",
              " 'course',\n",
              " 'courtries',\n",
              " 'cover',\n",
              " 'create',\n",
              " 'credit',\n",
              " 'creditcard',\n",
              " 'credited',\n",
              " 'cross-currency',\n",
              " 'crucial',\n",
              " 'crypto',\n",
              " 'cryptocurrency',\n",
              " 'currecy',\n",
              " 'currency',\n",
              " 'current',\n",
              " 'currently',\n",
              " 'customer',\n",
              " 'daily',\n",
              " 'damaged',\n",
              " 'damn',\n",
              " 'date',\n",
              " 'daughter',\n",
              " 'day',\n",
              " 'deactivate',\n",
              " 'deal',\n",
              " 'debit',\n",
              " 'debited',\n",
              " 'decide',\n",
              " 'decided',\n",
              " 'decline',\n",
              " 'declined',\n",
              " 'declining',\n",
              " 'deducted',\n",
              " 'deferred',\n",
              " 'definitely',\n",
              " 'delayed',\n",
              " 'delete',\n",
              " 'deliver',\n",
              " 'delivered',\n",
              " 'delivering',\n",
              " 'delivery',\n",
              " 'denied',\n",
              " 'denies',\n",
              " 'depart',\n",
              " 'departing',\n",
              " 'deposit',\n",
              " 'deposited',\n",
              " 'depositing',\n",
              " 'desperate',\n",
              " 'desperately',\n",
              " 'despite',\n",
              " 'detail',\n",
              " 'detect',\n",
              " 'determine',\n",
              " 'determined',\n",
              " 'device',\n",
              " 'devoid',\n",
              " 'did',\n",
              " 'didnt',\n",
              " 'difference',\n",
              " 'different',\n",
              " 'difficulty',\n",
              " 'digit',\n",
              " 'digitally',\n",
              " 'dinner',\n",
              " 'direct',\n",
              " 'directed',\n",
              " 'direction',\n",
              " 'directly',\n",
              " 'diret',\n",
              " 'disable',\n",
              " 'disallowed',\n",
              " 'disappeared',\n",
              " 'disappointed',\n",
              " 'discontinue',\n",
              " 'discount',\n",
              " 'discus',\n",
              " 'dispatched',\n",
              " 'displaying',\n",
              " 'disposable',\n",
              " 'dispose',\n",
              " 'dispute',\n",
              " 'disputing',\n",
              " 'dissatisfied',\n",
              " 'do',\n",
              " 'document',\n",
              " 'doe',\n",
              " 'doing',\n",
              " 'dollar',\n",
              " 'done',\n",
              " 'dont',\n",
              " 'double',\n",
              " 'double-check',\n",
              " 'double-checked',\n",
              " 'down',\n",
              " 'dp',\n",
              " 'draw',\n",
              " 'drunk',\n",
              " 'due',\n",
              " 'duplicate',\n",
              " 'duplicated',\n",
              " 'during',\n",
              " 'each',\n",
              " 'earlier',\n",
              " 'early',\n",
              " 'earth',\n",
              " 'easy',\n",
              " 'eat',\n",
              " 'eating',\n",
              " 'eats',\n",
              " 'economic',\n",
              " 'edit',\n",
              " 'effect',\n",
              " 'either',\n",
              " 'elaborate',\n",
              " 'eligible',\n",
              " 'else',\n",
              " 'email',\n",
              " 'embarrassing',\n",
              " 'emergency',\n",
              " 'employer',\n",
              " 'employment',\n",
              " 'empty',\n",
              " 'enabled',\n",
              " 'end',\n",
              " 'enetered',\n",
              " 'enough',\n",
              " 'ensure',\n",
              " 'enter',\n",
              " 'entered',\n",
              " 'entering',\n",
              " 'entry',\n",
              " 'equal',\n",
              " 'equating',\n",
              " 'error',\n",
              " 'essential',\n",
              " 'establishment',\n",
              " 'estimated',\n",
              " 'eu',\n",
              " 'eur',\n",
              " 'euro',\n",
              " 'europe',\n",
              " 'european',\n",
              " 'even',\n",
              " 'every',\n",
              " 'everybody',\n",
              " 'everyday',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'evidently',\n",
              " 'exactly',\n",
              " 'exceeded',\n",
              " 'exchange',\n",
              " 'exchanged',\n",
              " 'exchanging',\n",
              " 'exist',\n",
              " 'existing',\n",
              " 'expect',\n",
              " 'expected',\n",
              " 'expecting',\n",
              " 'expedite',\n",
              " 'expedition',\n",
              " 'expensive',\n",
              " 'expiration',\n",
              " 'expire',\n",
              " 'expired',\n",
              " 'expires',\n",
              " 'expiring',\n",
              " 'explain',\n",
              " 'explaining',\n",
              " 'explanation',\n",
              " 'express',\n",
              " 'extra',\n",
              " 'extremely',\n",
              " 'fact',\n",
              " 'factual',\n",
              " 'fail',\n",
              " 'failed',\n",
              " 'failing',\n",
              " 'fails',\n",
              " 'failure',\n",
              " 'false',\n",
              " 'familiar',\n",
              " 'family',\n",
              " 'far',\n",
              " 'fare',\n",
              " 'fast',\n",
              " 'faster',\n",
              " 'fear',\n",
              " 'feature',\n",
              " 'fee',\n",
              " 'feel',\n",
              " 'few',\n",
              " 'fiat',\n",
              " 'fiduciary',\n",
              " 'figue',\n",
              " 'figure',\n",
              " 'figuring',\n",
              " 'file',\n",
              " 'fill',\n",
              " 'finalized',\n",
              " 'finally',\n",
              " 'find',\n",
              " 'finding',\n",
              " 'fine',\n",
              " 'fined',\n",
              " 'finish',\n",
              " 'finished',\n",
              " 'first',\n",
              " 'five',\n",
              " 'fix',\n",
              " 'fixed',\n",
              " 'fixing',\n",
              " 'flat',\n",
              " 'fluffy',\n",
              " 'follow',\n",
              " 'following',\n",
              " 'for',\n",
              " 'foreign',\n",
              " 'forever',\n",
              " 'forewarned',\n",
              " 'forget',\n",
              " 'forgetting',\n",
              " 'forgot',\n",
              " 'forgotten',\n",
              " 'form',\n",
              " 'format',\n",
              " 'formula',\n",
              " 'forth',\n",
              " 'forward',\n",
              " 'found',\n",
              " 'frame',\n",
              " 'france',\n",
              " 'fraud',\n",
              " 'fraudulent',\n",
              " 'fraudulently',\n",
              " 'free',\n",
              " 'freeze',\n",
              " 'freezing',\n",
              " 'frequent',\n",
              " 'frequently',\n",
              " 'friend',\n",
              " 'from',\n",
              " 'frozen',\n",
              " 'frustrating',\n",
              " 'full',\n",
              " 'fully',\n",
              " 'function',\n",
              " 'functioning',\n",
              " 'fund',\n",
              " 'further',\n",
              " 'future',\n",
              " 'gained',\n",
              " 'gas',\n",
              " 'gave',\n",
              " 'gbp',\n",
              " 'generating',\n",
              " 'get',\n",
              " 'getting',\n",
              " 'girl',\n",
              " 'give',\n",
              " 'given',\n",
              " 'giving',\n",
              " 'glare',\n",
              " 'glitch',\n",
              " 'globally',\n",
              " 'go',\n",
              " 'god',\n",
              " 'goin',\n",
              " 'going',\n",
              " 'gon',\n",
              " 'gone',\n",
              " 'good',\n",
              " 'goofed',\n",
              " 'google',\n",
              " 'got',\n",
              " 'gotten',\n",
              " 'gpb',\n",
              " 'grandson',\n",
              " 'greatest',\n",
              " 'grocery',\n",
              " 'growing',\n",
              " 'guess',\n",
              " 'guide',\n",
              " 'guideline',\n",
              " 'guy',\n",
              " 'gym',\n",
              " 'ha',\n",
              " 'hacked',\n",
              " 'had',\n",
              " 'half',\n",
              " 'hand',\n",
              " 'handful',\n",
              " 'handle',\n",
              " 'happen',\n",
              " 'happend',\n",
              " 'happened',\n",
              " 'happening',\n",
              " 'happenning',\n",
              " 'happens',\n",
              " 'happy',\n",
              " 'hard',\n",
              " 'hasnt',\n",
              " 'hassle',\n",
              " 'hate',\n",
              " 'have',\n",
              " 'having',\n",
              " 'havnt',\n",
              " 'he',\n",
              " 'hear',\n",
              " 'heard',\n",
              " 'hearing',\n",
              " 'hello',\n",
              " 'help',\n",
              " 'help-',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hey',\n",
              " 'hi',\n",
              " 'hidden',\n",
              " 'high',\n",
              " 'higher',\n",
              " 'highest',\n",
              " 'hill',\n",
              " 'his',\n",
              " 'history',\n",
              " 'hit',\n",
              " 'hoe',\n",
              " 'hold',\n",
              " 'holding',\n",
              " 'holiday',\n",
              " 'home',\n",
              " 'hometown',\n",
              " 'hope',\n",
              " 'hoping',\n",
              " 'horrible',\n",
              " 'hotel',\n",
              " 'hotel/',\n",
              " 'hour',\n",
              " 'hour.please',\n",
              " 'house',\n",
              " 'how',\n",
              " 'however',\n",
              " 'hundred',\n",
              " 'husband',\n",
              " 'i',\n",
              " 'id',\n",
              " 'idea',\n",
              " 'ideal',\n",
              " 'identification',\n",
              " 'identify',\n",
              " 'identity',\n",
              " 'identy',\n",
              " 'if',\n",
              " 'ii',\n",
              " 'im',\n",
              " 'image',\n",
              " 'immediately',\n",
              " 'important',\n",
              " 'impression',\n",
              " 'in',\n",
              " 'incase',\n",
              " 'incentive',\n",
              " 'include',\n",
              " 'incomplete',\n",
              " 'incorrect',\n",
              " 'incorrectly',\n",
              " 'increase',\n",
              " 'increased',\n",
              " 'increasing',\n",
              " 'increment',\n",
              " 'incurring',\n",
              " 'indentity',\n",
              " 'indicate',\n",
              " 'indicates',\n",
              " 'info',\n",
              " 'information',\n",
              " 'informed',\n",
              " 'initiated',\n",
              " 'initiating',\n",
              " 'input',\n",
              " 'inputting',\n",
              " 'inquire',\n",
              " 'inquiring',\n",
              " 'inside',\n",
              " 'insight',\n",
              " 'instant',\n",
              " 'instead',\n",
              " 'institution',\n",
              " 'instruction',\n",
              " 'insufficient',\n",
              " 'interbank',\n",
              " 'interbanks',\n",
              " 'interested',\n",
              " 'international',\n",
              " 'internet',\n",
              " 'interval',\n",
              " 'into',\n",
              " 'invalidate',\n",
              " 'investigate',\n",
              " 'involved',\n",
              " 'is',\n",
              " 'isnt',\n",
              " 'issue',\n",
              " 'issued',\n",
              " 'it',\n",
              " 'item',\n",
              " 'itself',\n",
              " 'ive',\n",
              " 'jacket',\n",
              " 'just',\n",
              " 'keep',\n",
              " 'kensington',\n",
              " 'kept',\n",
              " 'keyed',\n",
              " 'kicking',\n",
              " 'kid',\n",
              " 'kind',\n",
              " 'knew',\n",
              " 'know',\n",
              " 'knowledge',\n",
              " 'known',\n",
              " 'landlord',\n",
              " 'large',\n",
              " 'larger',\n",
              " 'last',\n",
              " 'latest',\n",
              " 'le',\n",
              " 'learning',\n",
              " 'least',\n",
              " 'left',\n",
              " 'legit',\n",
              " 'length',\n",
              " 'lesser',\n",
              " 'let',\n",
              " 'letting',\n",
              " 'life',\n",
              " 'like',\n",
              " 'limit',\n",
              " 'limitation',\n",
              " 'limited',\n",
              " 'line',\n",
              " 'link',\n",
              " 'linked',\n",
              " 'list',\n",
              " 'listed',\n",
              " 'little',\n",
              " 'live',\n",
              " 'living',\n",
              " 'local',\n",
              " 'locate',\n",
              " 'located',\n",
              " 'location',\n",
              " 'locked',\n",
              " 'log',\n",
              " 'logged',\n",
              " 'login',\n",
              " 'long',\n",
              " 'longer',\n",
              " 'longest',\n",
              " 'look',\n",
              " 'looked',\n",
              " 'looking',\n",
              " 'lookup',\n",
              " 'loose',\n",
              " 'lose',\n",
              " 'lost',\n",
              " 'lot',\n",
              " 'low',\n",
              " 'machine',\n",
              " 'made',\n",
              " 'mail',\n",
              " 'mailed',\n",
              " 'make',\n",
              " 'making',\n",
              " 'manage',\n",
              " 'managed',\n",
              " 'many',\n",
              " 'marriage',\n",
              " 'married',\n",
              " 'mastecard',\n",
              " 'mastercard',\n",
              " 'mastercards',\n",
              " 'match',\n",
              " 'matter',\n",
              " 'max',\n",
              " 'maximum',\n",
              " 'may',\n",
              " 'maybe',\n",
              " 'mcdonalds',\n",
              " 'me',\n",
              " 'mean',\n",
              " 'meantime',\n",
              " 'membership',\n",
              " 'merchant',\n",
              " 'mess',\n",
              " 'message',\n",
              " 'messed',\n",
              " 'method',\n",
              " 'metro',\n",
              " 'middle',\n",
              " 'might',\n",
              " 'mile',\n",
              " 'mind',\n",
              " 'mine',\n",
              " 'minimum',\n",
              " 'minor',\n",
              " 'minute',\n",
              " 'mis-typed',\n",
              " 'misplaced',\n",
              " 'missing',\n",
              " 'mistake',\n",
              " 'mistook',\n",
              " 'mobile',\n",
              " 'modified',\n",
              " 'modify',\n",
              " 'moment',\n",
              " 'money',\n",
              " 'month',\n",
              " 'monthly',\n",
              " 'more',\n",
              " 'morning',\n",
              " 'mortgage',\n",
              " 'most',\n",
              " 'move',\n",
              " 'moved',\n",
              " 'movie',\n",
              " 'much',\n",
              " 'mugged',\n",
              " 'multiple',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'mysterious',\n",
              " \"n't\",\n",
              " 'na',\n",
              " 'name',\n",
              " 'native',\n",
              " 'nearby',\n",
              " 'nearest',\n",
              " 'nearly',\n",
              " 'necessary',\n",
              " 'need',\n",
              " 'needed',\n",
              " 'needing',\n",
              " 'negating',\n",
              " 'netflix',\n",
              " 'never',\n",
              " 'new',\n",
              " 'next',\n",
              " 'night',\n",
              " 'no',\n",
              " 'non-functional',\n",
              " 'non-received',\n",
              " 'nor',\n",
              " 'normal',\n",
              " 'normally',\n",
              " 'not',\n",
              " 'note',\n",
              " 'nothing',\n",
              " 'notice',\n",
              " 'noticed',\n",
              " 'noticing',\n",
              " 'notting',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'number',\n",
              " 'obtain',\n",
              " 'obvious',\n",
              " 'occasion',\n",
              " 'occurred',\n",
              " 'odd',\n",
              " 'of',\n",
              " 'off',\n",
              " 'offer',\n",
              " 'offered',\n",
              " 'office',\n",
              " 'official',\n",
              " 'often',\n",
              " 'oh',\n",
              " 'ok',\n",
              " 'okay',\n",
              " 'old',\n",
              " 'older',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'online',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'op',\n",
              " 'open',\n",
              " 'opening',\n",
              " 'operate',\n",
              " 'opinion',\n",
              " 'option',\n",
              " 'or',\n",
              " 'order',\n",
              " 'ordered',\n",
              " 'ordering',\n",
              " 'original',\n",
              " 'originally',\n",
              " 'originating',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'ought',\n",
              " 'our',\n",
              " 'out',\n",
              " 'outgoing',\n",
              " 'outregous',\n",
              " 'outside',\n",
              " 'over',\n",
              " 'overcharged',\n",
              " 'overseas',\n",
              " 'owe',\n",
              " 'own',\n",
              " 'pack',\n",
              " 'package',\n",
              " 'paid',\n",
              " 'panicking',\n",
              " 'parent',\n",
              " 'part',\n",
              " 'partial',\n",
              " 'particular',\n",
              " 'pas',\n",
              " 'pass-code',\n",
              " 'passcode',\n",
              " 'passed',\n",
              " 'passocde',\n",
              " 'password',\n",
              " 'past',\n",
              " 'pattern',\n",
              " 'pay',\n",
              " 'payed',\n",
              " 'paying',\n",
              " 'payment',\n",
              " 'payment/purchase',\n",
              " 'payroll',\n",
              " 'pending',\n",
              " 'people',\n",
              " 'per',\n",
              " 'perform',\n",
              " 'performed',\n",
              " 'period',\n",
              " 'permission',\n",
              " 'permitted',\n",
              " 'person',\n",
              " 'personal',\n",
              " 'personally',\n",
              " 'peso',\n",
              " 'phone',\n",
              " 'photo',\n",
              " 'physical',\n",
              " 'physically',\n",
              " 'pick',\n",
              " 'piece',\n",
              " 'pin',\n",
              " 'place',\n",
              " 'placed',\n",
              " 'platform',\n",
              " 'play',\n",
              " 'please',\n",
              " 'pls',\n",
              " 'plug-in',\n",
              " 'pocket',\n",
              " 'point',\n",
              " 'police',\n",
              " 'policy',\n",
              " 'poor',\n",
              " 'pop',\n",
              " 'portugal',\n",
              " 'positive',\n",
              " 'posse',\n",
              " 'possession',\n",
              " 'possibility',\n",
              " 'possible',\n",
              " 'possibly',\n",
              " 'post',\n",
              " 'posted',\n",
              " 'pound',\n",
              " ...]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xet0B7nQ1nYP"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "output = [0] * len(data_classes)\n",
        "for i, j in enumerate(x):\n",
        "    bag_of_words = []\n",
        "    text = lemmatizer.lemmatize(j.lower())\n",
        "    for word in words:\n",
        "        bag_of_words.append(1) if word in text else bag_of_words.append(0)\n",
        "\n",
        "    output_row = list(output)\n",
        "    output_row[data_classes.index(y[i])] = 1\n",
        "    training_data.append([bag_of_words, output_row])\n",
        "\n",
        "random.shuffle(training_data)\n",
        "training_data = num.array(training_data, dtype=object)\n",
        "\n",
        "xp = num.array(list(training_data[:, 0]))\n",
        "yp = num.array(list(training_data[:, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsLPffoN10u4",
        "outputId": "504f7f91-5023-4fae-da00-9b0f55435222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               400640    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 77)                9933      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 443469 (1.69 MB)\n",
            "Trainable params: 443469 (1.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "120/120 [==============================] - 2s 7ms/step - loss: 4.1206 - accuracy: 0.0729\n",
            "Epoch 2/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 2.6965 - accuracy: 0.3447\n",
            "Epoch 3/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.6512 - accuracy: 0.5706\n",
            "Epoch 4/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.1591 - accuracy: 0.6900\n",
            "Epoch 5/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.8913 - accuracy: 0.7603\n",
            "Epoch 6/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.7232 - accuracy: 0.8001\n",
            "Epoch 7/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.6190 - accuracy: 0.8265\n",
            "Epoch 8/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.5369 - accuracy: 0.8510\n",
            "Epoch 9/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.8706\n",
            "Epoch 10/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.8850\n",
            "Epoch 11/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.3643 - accuracy: 0.8941\n",
            "Epoch 12/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.3320 - accuracy: 0.9064\n",
            "Epoch 13/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2908 - accuracy: 0.9145\n",
            "Epoch 14/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2722 - accuracy: 0.9232\n",
            "Epoch 15/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2474 - accuracy: 0.9307\n",
            "Epoch 16/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2253 - accuracy: 0.9336\n",
            "Epoch 17/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2108 - accuracy: 0.9407\n",
            "Epoch 18/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1964 - accuracy: 0.9441\n",
            "Epoch 19/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1814 - accuracy: 0.9482\n",
            "Epoch 20/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1765 - accuracy: 0.9503\n",
            "Epoch 21/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1527 - accuracy: 0.9584\n",
            "Epoch 22/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1541 - accuracy: 0.9535\n",
            "Epoch 23/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1422 - accuracy: 0.9556\n",
            "Epoch 24/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1246 - accuracy: 0.9684\n",
            "Epoch 25/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1215 - accuracy: 0.9671\n",
            "Epoch 26/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1147 - accuracy: 0.9671\n",
            "Epoch 27/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9702\n",
            "Epoch 28/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.1028 - accuracy: 0.9705\n",
            "Epoch 29/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.1026 - accuracy: 0.9705\n",
            "Epoch 30/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0963 - accuracy: 0.9739\n",
            "Epoch 31/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0969 - accuracy: 0.9697\n",
            "Epoch 32/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0908 - accuracy: 0.9726\n",
            "Epoch 33/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9760\n",
            "Epoch 34/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0813 - accuracy: 0.9778\n",
            "Epoch 35/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0712 - accuracy: 0.9783\n",
            "Epoch 36/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9780\n",
            "Epoch 37/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0671 - accuracy: 0.9804\n",
            "Epoch 38/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0725 - accuracy: 0.9775\n",
            "Epoch 39/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0681 - accuracy: 0.9791\n",
            "Epoch 40/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0691 - accuracy: 0.9788\n",
            "Epoch 41/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0877 - accuracy: 0.9739\n",
            "Epoch 42/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0640 - accuracy: 0.9786\n",
            "Epoch 43/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0740 - accuracy: 0.9773\n",
            "Epoch 44/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0565 - accuracy: 0.9835\n",
            "Epoch 45/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0614 - accuracy: 0.9841\n",
            "Epoch 46/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0587 - accuracy: 0.9809\n",
            "Epoch 47/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0588 - accuracy: 0.9830\n",
            "Epoch 48/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9804\n",
            "Epoch 49/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0569 - accuracy: 0.9804\n",
            "Epoch 50/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9835\n",
            "Epoch 51/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9875\n",
            "Epoch 52/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9856\n",
            "Epoch 53/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0526 - accuracy: 0.9835\n",
            "Epoch 54/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9859\n",
            "Epoch 55/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0495 - accuracy: 0.9825\n",
            "Epoch 56/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9869\n",
            "Epoch 57/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0426 - accuracy: 0.9880\n",
            "Epoch 58/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9885\n",
            "Epoch 59/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0462 - accuracy: 0.9854\n",
            "Epoch 60/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9859\n",
            "Epoch 61/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0406 - accuracy: 0.9893\n",
            "Epoch 62/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9859\n",
            "Epoch 63/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.9885\n",
            "Epoch 64/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9854\n",
            "Epoch 65/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9859\n",
            "Epoch 66/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0443 - accuracy: 0.9875\n",
            "Epoch 67/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0445 - accuracy: 0.9848\n",
            "Epoch 68/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9877\n",
            "Epoch 69/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9867\n",
            "Epoch 70/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9890\n",
            "Epoch 71/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9869\n",
            "Epoch 72/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9888\n",
            "Epoch 73/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0394 - accuracy: 0.9882\n",
            "Epoch 74/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9880\n",
            "Epoch 75/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9909\n",
            "Epoch 76/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9851\n",
            "Epoch 77/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0357 - accuracy: 0.9885\n",
            "Epoch 78/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9890\n",
            "Epoch 79/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9890\n",
            "Epoch 80/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9880\n",
            "Epoch 81/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0409 - accuracy: 0.9861\n",
            "Epoch 82/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9893\n",
            "Epoch 83/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9861\n",
            "Epoch 84/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9906\n",
            "Epoch 85/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9875\n",
            "Epoch 86/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9903\n",
            "Epoch 87/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9895\n",
            "Epoch 88/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9885\n",
            "Epoch 89/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9906\n",
            "Epoch 90/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9916\n",
            "Epoch 91/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9916\n",
            "Epoch 92/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9890\n",
            "Epoch 93/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9903\n",
            "Epoch 94/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0292 - accuracy: 0.9898\n",
            "Epoch 95/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9911\n",
            "Epoch 96/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0287 - accuracy: 0.9909\n",
            "Epoch 97/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9885\n",
            "Epoch 98/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0278 - accuracy: 0.9906\n",
            "Epoch 99/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9869\n",
            "Epoch 100/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9890\n",
            "Epoch 101/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0262 - accuracy: 0.9914\n",
            "Epoch 102/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9922\n",
            "Epoch 103/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9890\n",
            "Epoch 104/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9893\n",
            "Epoch 105/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9916\n",
            "Epoch 106/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9880\n",
            "Epoch 107/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0262 - accuracy: 0.9906\n",
            "Epoch 108/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9914\n",
            "Epoch 109/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0260 - accuracy: 0.9911\n",
            "Epoch 110/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0248 - accuracy: 0.9916\n",
            "Epoch 111/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0203 - accuracy: 0.9935\n",
            "Epoch 112/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0290 - accuracy: 0.9919\n",
            "Epoch 113/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9937\n",
            "Epoch 114/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0342 - accuracy: 0.9893\n",
            "Epoch 115/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0297 - accuracy: 0.9916\n",
            "Epoch 116/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0240 - accuracy: 0.9927\n",
            "Epoch 117/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9888\n",
            "Epoch 118/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9890\n",
            "Epoch 119/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0276 - accuracy: 0.9906\n",
            "Epoch 120/200\n",
            "120/120 [==============================] - 1s 9ms/step - loss: 0.0217 - accuracy: 0.9940\n",
            "Epoch 121/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0246 - accuracy: 0.9922\n",
            "Epoch 122/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9909\n",
            "Epoch 123/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0210 - accuracy: 0.9927\n",
            "Epoch 124/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0229 - accuracy: 0.9937\n",
            "Epoch 125/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9906\n",
            "Epoch 126/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0267 - accuracy: 0.9922\n",
            "Epoch 127/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0261 - accuracy: 0.9906\n",
            "Epoch 128/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9903\n",
            "Epoch 129/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0291 - accuracy: 0.9901\n",
            "Epoch 130/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0232 - accuracy: 0.9924\n",
            "Epoch 131/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9935\n",
            "Epoch 132/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9922\n",
            "Epoch 133/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9937\n",
            "Epoch 134/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9919\n",
            "Epoch 135/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0188 - accuracy: 0.9940\n",
            "Epoch 136/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.9950\n",
            "Epoch 137/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0248 - accuracy: 0.9909\n",
            "Epoch 138/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9914\n",
            "Epoch 139/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9916\n",
            "Epoch 140/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9937\n",
            "Epoch 141/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9924\n",
            "Epoch 142/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0276 - accuracy: 0.9909\n",
            "Epoch 143/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9914\n",
            "Epoch 144/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9911\n",
            "Epoch 145/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9919\n",
            "Epoch 146/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9937\n",
            "Epoch 147/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0272 - accuracy: 0.9916\n",
            "Epoch 148/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0210 - accuracy: 0.9919\n",
            "Epoch 149/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0220 - accuracy: 0.9927\n",
            "Epoch 150/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9932\n",
            "Epoch 151/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0250 - accuracy: 0.9924\n",
            "Epoch 152/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0234 - accuracy: 0.9914\n",
            "Epoch 153/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9924\n",
            "Epoch 154/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9927\n",
            "Epoch 155/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9932\n",
            "Epoch 156/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9929\n",
            "Epoch 157/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9893\n",
            "Epoch 158/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0227 - accuracy: 0.9935\n",
            "Epoch 159/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9932\n",
            "Epoch 160/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9911\n",
            "Epoch 161/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0255 - accuracy: 0.9916\n",
            "Epoch 162/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0245 - accuracy: 0.9924\n",
            "Epoch 163/200\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9909\n",
            "Epoch 164/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0230 - accuracy: 0.9940\n",
            "Epoch 165/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0191 - accuracy: 0.9948\n",
            "Epoch 166/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9935\n",
            "Epoch 167/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 0.9963\n",
            "Epoch 168/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0187 - accuracy: 0.9929\n",
            "Epoch 169/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9903\n",
            "Epoch 170/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0229 - accuracy: 0.9922\n",
            "Epoch 171/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9932\n",
            "Epoch 172/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9919\n",
            "Epoch 173/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9948\n",
            "Epoch 174/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0184 - accuracy: 0.9932\n",
            "Epoch 175/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9945\n",
            "Epoch 176/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0211 - accuracy: 0.9927\n",
            "Epoch 177/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9937\n",
            "Epoch 178/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0261 - accuracy: 0.9919\n",
            "Epoch 179/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0222 - accuracy: 0.9919\n",
            "Epoch 180/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0229 - accuracy: 0.9911\n",
            "Epoch 181/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9924\n",
            "Epoch 182/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0179 - accuracy: 0.9932\n",
            "Epoch 183/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0172 - accuracy: 0.9956\n",
            "Epoch 184/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9948\n",
            "Epoch 185/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 0.9953\n",
            "Epoch 186/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0206 - accuracy: 0.9932\n",
            "Epoch 187/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0234 - accuracy: 0.9927\n",
            "Epoch 188/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0188 - accuracy: 0.9942\n",
            "Epoch 189/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0210 - accuracy: 0.9929\n",
            "Epoch 190/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0201 - accuracy: 0.9935\n",
            "Epoch 191/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0196 - accuracy: 0.9927\n",
            "Epoch 192/200\n",
            "120/120 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9922\n",
            "Epoch 193/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0192 - accuracy: 0.9940\n",
            "Epoch 194/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9948\n",
            "Epoch 195/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9929\n",
            "Epoch 196/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9953\n",
            "Epoch 197/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9924\n",
            "Epoch 198/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0267 - accuracy: 0.9916\n",
            "Epoch 199/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0157 - accuracy: 0.9950\n",
            "Epoch 200/200\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.0153 - accuracy: 0.9953\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x251bc9a75b0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shape_x = (len(xp[0]),)\n",
        "shape_y = len(yp[0])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=shape_x, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(shape_y, activation=\"softmax\"))\n",
        "op = tensorF.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=op, metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(xp, yp, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found model file at  models/ggml-gpt4all-j-v1.3-groovy.bin\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import GPT4All\n",
        "\n",
        "llm = GPT4All(model=\"models/ggml-gpt4all-j-v1.3-groovy.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"What can I do for you regarding transferring timing?\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'intent': 'User has query related to User has query related to transfer_timing',\n",
              " 'text': '\"What can I do for you regarding transferring timing?\"'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "template = \"\"\"\n",
        "You are engaged in a User Intent Detection project inside a bank.\n",
        "You will be given a possible intent of user.\n",
        "You are the manager of bank and ask questions to user to understand their query.\n",
        "The possible user intent is {intent}\n",
        "Give the question to be asked by manager to user in not more than 10 words.\n",
        "Based on all the thoughts the question to ask in the domain of this intent is:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_gpt_response(user_intent):\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"intent\"])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=False)\n",
        "\n",
        "    return llm_chain(\"User has query related to \" + user_intent)\n",
        "\n",
        "\n",
        "get_gpt_response(\"transfer_timing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Are you aware that your account's PIN number might have been blocked due to insufficient security measures, and if so how can we help you unblock it?\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'intent': 'User has query related to pin_blocked',\n",
              " 'text': '\"Are you aware that your account\\'s PIN number might have been blocked due to insufficient security measures, and if so how can we help you unblock it?\"'}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_gpt_response(\"pin_blocked\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uwCV1uh413AM"
      },
      "outputs": [],
      "source": [
        "def text(txt):\n",
        "    tokens = nltk.word_tokenize(txt)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def word_bag(txt, vocab):\n",
        "    tokens = text(txt)\n",
        "    bag_words = [0] * len(vocab)\n",
        "    for i in tokens:\n",
        "        for idx, word in enumerate(vocab):\n",
        "            if word == i:\n",
        "                bag_words[idx] = 1\n",
        "    return num.array(bag_words)\n",
        "\n",
        "\n",
        "def predict_class(txt, vocab, labels):\n",
        "    bag_words = word_bag(txt, vocab)\n",
        "    result = model.predict(num.array([bag_words]))[0]\n",
        "    threshold = 0.01\n",
        "    y_prob = [[idx, res] for idx, res in enumerate(result) if res > threshold]\n",
        "    y_prob.sort(key=lambda x: x[1], reverse=True)\n",
        "    list_y = []\n",
        "    for i in y_prob:\n",
        "        list_y.append(labels[i[0]])\n",
        "    print()\n",
        "    return list_y\n",
        "\n",
        "\n",
        "def get_result(result_list):\n",
        "    result = []\n",
        "    for tag in result_list:\n",
        "        result.append(get_gpt_response(tag)[\"text\"])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xwg0zAcHg2gb",
        "outputId": "6e8b91f8-0480-4573-e553-04824b39686d"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "iterations = 3\n",
        "\n",
        "while True:\n",
        "    count += 1\n",
        "    message = input(\"\")\n",
        "\n",
        "    if message == \"Exit\":\n",
        "        break\n",
        "    print(\"Query:\", message)\n",
        "    intents = predict_class(message, words, data_classes)\n",
        "    print(\"Possible Intents:\", intents)\n",
        "    if count >= iterations and len(intents) == 1:\n",
        "        break\n",
        "    response = get_result(intents)\n",
        "    print(\"Response:\", response)\n",
        "\n",
        "print(\"User Intent Finally:\", intents)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
